{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# vxdb Quickstart\n",
        "\n",
        "This notebook walks you through every core feature of **vxdb** in under 5 minutes.\n",
        "\n",
        "No API keys needed — we use small dummy vectors so you can run every cell immediately.\n",
        "\n",
        "**What you'll learn:**\n",
        "1. Create a database and collection\n",
        "2. Insert vectors with metadata and documents\n",
        "3. Vector similarity search\n",
        "4. Filtered search (metadata operators)\n",
        "5. Hybrid search (vector + keyword)\n",
        "6. Pure keyword search\n",
        "7. Update and delete operations\n",
        "8. Multiple collections"
      ],
      "id": "b7581330"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install vxdb -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement vxdb (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for vxdb\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "id": "c0fef4eb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create a Database and Collection\n",
        "\n",
        "A **Database** holds multiple **Collections**. Each collection stores vectors of a fixed dimension with a chosen distance metric and index type.\n",
        "\n",
        "Pass `path=` to persist data to disk (survives restarts). Omit it for a fast, ephemeral in-memory database.\n",
        "\n",
        "| Parameter | Options | Default |\n",
        "|-----------|---------|---------| \n",
        "| `path` | Any directory path, or `None` | `None` (in-memory) |\n",
        "| `metric` | `\"cosine\"`, `\"euclidean\"`, `\"dot\"` | `\"cosine\"` |\n",
        "| `index` | `\"flat\"` (exact brute-force), `\"hnsw\"` (approximate, faster for large datasets) | `\"flat\"` |"
      ],
      "id": "fff8d5b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import vxdb\n",
        "\n",
        "# Persistent — data survives restarts (recommended for real usage)\n",
        "# db = vxdb.Database(path=\"./quickstart_data\")\n",
        "\n",
        "# In-memory — fast and ephemeral (used here so the notebook is self-contained)\n",
        "db = vxdb.Database()\n",
        "\n",
        "# dimension = number of floats per vector (must match your embedding model)\n",
        "collection = db.create_collection(\n",
        "    name=\"articles\",\n",
        "    dimension=4,        # small for demo — real models use 384, 768, 1536, etc.\n",
        "    metric=\"cosine\",    # cosine similarity (most common for text embeddings)\n",
        "    index=\"flat\",       # exact search — switch to \"hnsw\" for >100k vectors\n",
        ")\n",
        "\n",
        "print(f\"Created: {collection}\")\n",
        "print(f\"Collections in db: {db.list_collections()}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created: Collection(name='articles')\n",
            "Collections in db: ['articles']\n"
          ]
        }
      ],
      "id": "a4515977"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Insert Vectors\n",
        "\n",
        "Use `upsert()` to insert or update vectors. Each vector needs:\n",
        "- **id** — a unique string identifier\n",
        "- **vector** — a list of floats (must match the collection's dimension)\n",
        "- **metadata** *(optional)* — a dict of key-value pairs for filtering\n",
        "- **documents** *(optional)* — raw text strings to enable hybrid/keyword search"
      ],
      "id": "bf69430e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# In a real app, these vectors come from an embedding model (see the other notebooks).\n",
        "# Here we use small 4-d vectors to keep things readable.\n",
        "\n",
        "collection.upsert(\n",
        "    ids=[\"doc1\", \"doc2\", \"doc3\", \"doc4\", \"doc5\"],\n",
        "    vectors=[\n",
        "        [1.0, 0.0, 0.0, 0.0],  # doc1: points in the \"x\" direction\n",
        "        [0.0, 1.0, 0.0, 0.0],  # doc2: points in the \"y\" direction\n",
        "        [0.9, 0.1, 0.0, 0.0],  # doc3: very similar to doc1\n",
        "        [0.0, 0.0, 1.0, 0.0],  # doc4: points in the \"z\" direction\n",
        "        [0.5, 0.5, 0.0, 0.0],  # doc5: between doc1 and doc2\n",
        "    ],\n",
        "    metadata=[\n",
        "        {\"title\": \"Intro to ML\",    \"category\": \"tech\",      \"year\": 2024},\n",
        "        {\"title\": \"Cooking Pasta\",   \"category\": \"food\",      \"year\": 2023},\n",
        "        {\"title\": \"Advanced ML\",     \"category\": \"tech\",      \"year\": 2024},\n",
        "        {\"title\": \"Gardening 101\",   \"category\": \"lifestyle\", \"year\": 2022},\n",
        "        {\"title\": \"Data Science\",    \"category\": \"tech\",      \"year\": 2023},\n",
        "    ],\n",
        "    documents=[\n",
        "        \"Introduction to machine learning and neural networks\",\n",
        "        \"How to cook perfect pasta with homemade sauce\",\n",
        "        \"Advanced machine learning techniques and optimization\",\n",
        "        \"A beginner's guide to gardening and growing vegetables\",\n",
        "        \"Data science fundamentals with Python and statistics\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(f\"Inserted {collection.count()} vectors\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inserted 5 vectors\n"
          ]
        }
      ],
      "id": "907a90e5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Vector Similarity Search\n",
        "\n",
        "Pass a query vector and get back the closest matches, ranked by distance (lower = more similar for cosine)."
      ],
      "id": "491a04d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query_vector = [1.0, 0.0, 0.0, 0.0]  # looking for docs similar to doc1\n",
        "\n",
        "results = collection.query(vector=query_vector, top_k=3)\n",
        "\n",
        "print(\"Vector Search — top 3 closest to [1, 0, 0, 0]:\\n\")\n",
        "for r in results:\n",
        "    print(f\"  {r['id']:>5}  score={r['score']:.4f}  {r['metadata']['title']}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector Search — top 3 closest to [1, 0, 0, 0]:\n",
            "\n",
            "   doc1  score=0.0000  Intro to ML\n",
            "   doc3  score=0.0061  Advanced ML\n",
            "   doc5  score=0.2929  Data Science\n"
          ]
        }
      ],
      "id": "2b81c4ba"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Filtered Search\n",
        "\n",
        "Narrow results using metadata filters. vxdb supports 10 operators:\n",
        "\n",
        "| Operator | Meaning |\n",
        "|----------|---------|\n",
        "| `$eq` | equals |\n",
        "| `$ne` | not equals |\n",
        "| `$gt` / `$gte` | greater than / greater-or-equal |\n",
        "| `$lt` / `$lte` | less than / less-or-equal |\n",
        "| `$in` / `$nin` | in list / not in list |\n",
        "| `$and` / `$or` | combine conditions |"
      ],
      "id": "4059d381"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Only return tech articles from 2024 or later\n",
        "results = collection.query(\n",
        "    vector=query_vector,\n",
        "    top_k=5,\n",
        "    filter={\n",
        "        \"$and\": [\n",
        "            {\"category\": {\"$eq\": \"tech\"}},\n",
        "            {\"year\": {\"$gte\": 2024}},\n",
        "        ]\n",
        "    },\n",
        ")\n",
        "\n",
        "print(\"Filtered Search — tech articles, year >= 2024:\\n\")\n",
        "for r in results:\n",
        "    print(f\"  {r['id']:>5}  score={r['score']:.4f}  {r['metadata']}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filtered Search — tech articles, year >= 2024:\n",
            "\n",
            "   doc1  score=0.0000  {'year': 2024, 'title': 'Intro to ML', 'category': 'tech'}\n",
            "   doc3  score=0.0061  {'year': 2024, 'category': 'tech', 'title': 'Advanced ML'}\n"
          ]
        }
      ],
      "id": "361e8c2c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Hybrid Search (Vector + Keyword)\n",
        "\n",
        "Hybrid search combines **vector similarity** with **BM25 keyword matching** using Reciprocal Rank Fusion (RRF).\n",
        "\n",
        "This is useful when semantic similarity alone isn't enough — e.g., searching for specific terms, product codes, or proper nouns that embeddings may not capture well.\n",
        "\n",
        "The `alpha` parameter controls the blend:\n",
        "- `alpha=1.0` → pure vector search\n",
        "- `alpha=0.5` → equal weight (default)\n",
        "- `alpha=0.0` → pure keyword search\n",
        "\n",
        "> **Note:** You must pass `documents=` during `upsert()` to use hybrid/keyword search."
      ],
      "id": "3ff2d556"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = collection.hybrid_query(\n",
        "    vector=query_vector,\n",
        "    query=\"machine learning\",\n",
        "    top_k=3,\n",
        "    alpha=0.5,\n",
        ")\n",
        "\n",
        "print(\"Hybrid Search — vector ≈ [1,0,0,0] + keywords 'machine learning':\\n\")\n",
        "for r in results:\n",
        "    print(f\"  {r['id']:>5}  score={r['score']:.4f}  {r['metadata']['title']}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hybrid Search — vector ≈ [1,0,0,0] + keywords 'machine learning':\n",
            "\n",
            "   doc3  score=0.0163  Advanced ML\n",
            "   doc1  score=0.0163  Intro to ML\n",
            "   doc5  score=0.0079  Data Science\n"
          ]
        }
      ],
      "id": "c4cc5ac5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Pure Keyword Search\n",
        "\n",
        "Search by text only, no vector needed. Uses BM25 scoring internally."
      ],
      "id": "c2b687c3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = collection.keyword_search(query=\"pasta sauce\", top_k=3)\n",
        "\n",
        "print(\"Keyword Search — 'pasta sauce':\\n\")\n",
        "for r in results:\n",
        "    print(f\"  {r['id']:>5}  score={r['score']:.4f}  {r['metadata']['title']}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keyword Search — 'pasta sauce':\n",
            "\n",
            "   doc2  score=2.6195  Cooking Pasta\n"
          ]
        }
      ],
      "id": "54086760"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Update and Delete\n",
        "\n",
        "- **Upsert with an existing ID** overwrites that vector, metadata, and document.\n",
        "- **Delete** removes vectors by ID and returns which ones were actually found."
      ],
      "id": "26f990b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Update: upsert with the same ID replaces everything\n",
        "collection.upsert(\n",
        "    ids=[\"doc1\"],\n",
        "    vectors=[[0.0, 0.0, 0.0, 1.0]],\n",
        "    metadata=[{\"title\": \"Intro to ML (revised)\", \"category\": \"tech\", \"year\": 2025}],\n",
        ")\n",
        "print(f\"After update: count = {collection.count()}\")\n",
        "\n",
        "# Delete by ID\n",
        "deleted = collection.delete(ids=[\"doc4\"])\n",
        "print(f\"Deleted doc4: {deleted}\")\n",
        "print(f\"After delete: count = {collection.count()}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After update: count = 5\n",
            "Deleted doc4: [True]\n",
            "After delete: count = 4\n"
          ]
        }
      ],
      "id": "ed1b453d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Multiple Collections\n",
        "\n",
        "A single database can hold many collections — useful for organizing different data types (text, images, audio) or different embedding models."
      ],
      "id": "159e914b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "db.create_collection(\"images\", dimension=512, metric=\"cosine\", index=\"hnsw\")\n",
        "db.create_collection(\"audio\", dimension=256, metric=\"euclidean\")\n",
        "\n",
        "print(f\"All collections: {sorted(db.list_collections())}\")\n",
        "\n",
        "db.delete_collection(\"audio\")\n",
        "print(f\"After deleting 'audio': {sorted(db.list_collections())}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All collections: ['articles', 'audio', 'images']\n",
            "After deleting 'audio': ['articles', 'images']\n"
          ]
        }
      ],
      "id": "ab6221c7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "You now know all the core operations. Check out the other notebooks in this directory to see how to plug in **real embedding models**:\n",
        "\n",
        "| Notebook | Embedding Source | API Key Needed? |\n",
        "|----------|-----------------|-----------------|\n",
        "| `openai_embeddings.ipynb` | OpenAI `text-embedding-3-small` | Yes |\n",
        "| `sentence_transformers.ipynb` | Hugging Face (runs locally) | No |\n",
        "| `langchain_integration.ipynb` | LangChain (any provider) | Depends |\n",
        "| `cohere_embeddings.ipynb` | Cohere `embed-v4.0` | Yes |\n",
        "| `hybrid_search.ipynb` | End-to-end hybrid search RAG pipeline | Depends |"
      ],
      "id": "6d27a2ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "db.list_collections()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['images', 'articles']"
            ]
          }
        }
      ],
      "id": "10b50d8a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [],
      "id": "7e151f87"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pyai3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}