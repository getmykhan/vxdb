{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenAI Embeddings + vxdb\n",
        "\n",
        "This notebook shows how to generate embeddings with **OpenAI's API** and store/search them in vxdb.\n",
        "\n",
        "**Model used:** `text-embedding-3-small` (1536 dimensions, $0.02 per 1M tokens)\n",
        "\n",
        "You can swap in `text-embedding-3-large` (3072 dims) for higher quality, or `text-embedding-ada-002` (1536 dims, legacy).\n",
        "\n",
        "**Prerequisites:**\n",
        "```bash\n",
        "pip install vxdb openai\n",
        "```\n",
        "\n",
        "**You'll need:** an OpenAI API key → https://platform.openai.com/api-keys"
      ],
      "id": "7602e162"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install vxdb openai -q"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e00706c1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Set up the OpenAI client\n",
        "\n",
        "Set your API key as an environment variable or paste it directly (not recommended for shared notebooks)."
      ],
      "id": "3f0508dd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Option 1: set env var before running — export OPENAI_API_KEY=\"sk-...\"\n",
        "# Option 2: pass directly (not recommended for shared notebooks)\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "EMBEDDING_DIM = 1536  # dimensions for text-embedding-3-small"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d7b18291"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Define an embedding helper\n",
        "\n",
        "The OpenAI API accepts batches of up to 2048 texts. We wrap it in a simple function."
      ],
      "id": "34fba10d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_embeddings(texts: list[str]) -> list[list[float]]:\n",
        "    \"\"\"Call the OpenAI embeddings API and return a list of vectors.\"\"\"\n",
        "    response = client.embeddings.create(\n",
        "        input=texts,\n",
        "        model=EMBEDDING_MODEL,\n",
        "    )\n",
        "    # The API returns embeddings in the same order as the input\n",
        "    return [item.embedding for item in response.data]\n",
        "\n",
        "\n",
        "# Quick test\n",
        "test_vec = get_embeddings([\"hello world\"])\n",
        "print(f\"Embedding dimension: {len(test_vec[0])}\")\n",
        "print(f\"First 5 values: {test_vec[0][:5]}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4d23a46c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Prepare your data\n",
        "\n",
        "We'll index a small collection of documents. In production, this could be paragraphs from PDFs, product descriptions, support tickets, etc."
      ],
      "id": "64f5062c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "documents = [\n",
        "    {\n",
        "        \"id\": \"ml-intro\",\n",
        "        \"text\": \"Machine learning is a subset of artificial intelligence that enables systems to learn from data without being explicitly programmed.\",\n",
        "        \"metadata\": {\"topic\": \"ml\", \"level\": \"beginner\"},\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"dl-intro\",\n",
        "        \"text\": \"Deep learning uses neural networks with many layers to model complex patterns in large amounts of data.\",\n",
        "        \"metadata\": {\"topic\": \"dl\", \"level\": \"beginner\"},\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"transformers\",\n",
        "        \"text\": \"Transformer models use self-attention mechanisms to process sequences in parallel, revolutionizing NLP tasks like translation and summarization.\",\n",
        "        \"metadata\": {\"topic\": \"nlp\", \"level\": \"intermediate\"},\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"rag\",\n",
        "        \"text\": \"Retrieval-Augmented Generation combines a retrieval system with a generative model, grounding LLM outputs in real documents to reduce hallucination.\",\n",
        "        \"metadata\": {\"topic\": \"rag\", \"level\": \"advanced\"},\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"vec-db\",\n",
        "        \"text\": \"Vector databases store high-dimensional embeddings and support fast approximate nearest-neighbor search for semantic similarity.\",\n",
        "        \"metadata\": {\"topic\": \"infrastructure\", \"level\": \"intermediate\"},\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"fine-tuning\",\n",
        "        \"text\": \"Fine-tuning adapts a pre-trained model to a specific task by continuing training on a smaller, domain-specific dataset.\",\n",
        "        \"metadata\": {\"topic\": \"ml\", \"level\": \"advanced\"},\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"Prepared {len(documents)} documents\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "b5490613"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Embed and insert into vxdb\n",
        "\n",
        "We embed all documents in a single batch call, then upsert into a vxdb collection."
      ],
      "id": "41b1b726"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import vxdb\n",
        "\n",
        "# Embed all texts in one batch call (cheaper and faster)\n",
        "texts = [doc[\"text\"] for doc in documents]\n",
        "vectors = get_embeddings(texts)\n",
        "\n",
        "# Create database and collection\n",
        "db = vxdb.Database()\n",
        "collection = db.create_collection(\n",
        "    name=\"openai_docs\",\n",
        "    dimension=EMBEDDING_DIM,\n",
        "    metric=\"cosine\",\n",
        "    index=\"flat\",\n",
        ")\n",
        "\n",
        "# Upsert: vectors + metadata + raw text for hybrid search\n",
        "collection.upsert(\n",
        "    ids=[doc[\"id\"] for doc in documents],\n",
        "    vectors=vectors,\n",
        "    metadata=[doc[\"metadata\"] for doc in documents],\n",
        "    documents=texts,\n",
        ")\n",
        "\n",
        "print(f\"Indexed {collection.count()} documents with {EMBEDDING_DIM}-dim OpenAI embeddings\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "dd0f02d8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Semantic search\n",
        "\n",
        "Embed the query with the same model, then search by vector similarity."
      ],
      "id": "740f3092"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query = \"How do I make my LLM more accurate with external knowledge?\"\n",
        "query_vector = get_embeddings([query])[0]\n",
        "\n",
        "results = collection.query(vector=query_vector, top_k=3)\n",
        "\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "for r in results:\n",
        "    print(f\"  [{r['id']}]  score={r['score']:.4f}  topic={r['metadata']['topic']}\")\n",
        "    # Find the original text for display\n",
        "    original = next(d[\"text\"] for d in documents if d[\"id\"] == r[\"id\"])\n",
        "    print(f\"    → {original[:100]}...\\n\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "00235dd2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Filtered semantic search\n",
        "\n",
        "Combine vector similarity with metadata constraints — e.g., only search beginner-level docs."
      ],
      "id": "a953d8af"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = collection.query(\n",
        "    vector=query_vector,\n",
        "    top_k=3,\n",
        "    filter={\"level\": {\"$eq\": \"beginner\"}},\n",
        ")\n",
        "\n",
        "print(\"Filtered to beginner-level docs only:\\n\")\n",
        "for r in results:\n",
        "    print(f\"  [{r['id']}]  score={r['score']:.4f}  {r['metadata']}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0edc7f07"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Hybrid search\n",
        "\n",
        "Combine vector similarity with keyword matching. Useful when you want to ensure results contain specific terms."
      ],
      "id": "f554d585"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = collection.hybrid_query(\n",
        "    vector=query_vector,\n",
        "    query=\"retrieval augmented generation hallucination\",\n",
        "    top_k=3,\n",
        "    alpha=0.5,\n",
        ")\n",
        "\n",
        "print(\"Hybrid search (vector + keyword):\\n\")\n",
        "for r in results:\n",
        "    print(f\"  [{r['id']}]  rrf_score={r['score']:.4f}  {r['metadata']}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "1c03c9c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using vxdb's EmbeddingFunction interface\n",
        "\n",
        "For cleaner code, you can wrap OpenAI into vxdb's pluggable `EmbeddingFunction` base class:"
      ],
      "id": "2b26d840"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from vxdb.embedding import EmbeddingFunction\n",
        "\n",
        "\n",
        "class OpenAIEmbedding(EmbeddingFunction):\n",
        "    \"\"\"Reusable wrapper around OpenAI's embedding API.\"\"\"\n",
        "\n",
        "    def __init__(self, model: str = \"text-embedding-3-small\"):\n",
        "        self.client = OpenAI()\n",
        "        self.model = model\n",
        "\n",
        "    def embed(self, texts: list[str]) -> list[list[float]]:\n",
        "        response = self.client.embeddings.create(input=texts, model=self.model)\n",
        "        return [item.embedding for item in response.data]\n",
        "\n",
        "\n",
        "# Usage:\n",
        "embedder = OpenAIEmbedding()\n",
        "vecs = embedder.embed([\"This is a test sentence.\"])\n",
        "print(f\"OpenAIEmbedding produced a {len(vecs[0])}-dim vector\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9b9b4bb7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}