{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hybrid Search Deep Dive\n",
        "\n",
        "This notebook explores **when and why** to use hybrid search, and how to tune the `alpha` parameter for best results.\n",
        "\n",
        "**Hybrid search** combines two retrieval strategies:\n",
        "1. **Vector search** — finds semantically similar documents (meaning-based)\n",
        "2. **Keyword search (BM25)** — finds documents containing exact terms (word-based)\n",
        "\n",
        "Results are merged via **Reciprocal Rank Fusion (RRF)**, which combines rankings from both systems without needing to normalize scores.\n",
        "\n",
        "**When to use hybrid search:**\n",
        "- Specific terms matter (product codes, proper nouns, error messages)\n",
        "- Users mix natural language with exact keywords\n",
        "- You want the best of both worlds without choosing\n",
        "\n",
        "**No API keys needed** — this notebook uses sentence-transformers (local, free).\n",
        "\n",
        "```bash\n",
        "pip install vxdb sentence-transformers\n",
        "```"
      ],
      "id": "48f1ef72"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install vxdb sentence-transformers -q"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "afeee9a2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Build a product catalog\n",
        "\n",
        "We'll use a realistic scenario — a tech product catalog where users search with a mix of natural language and specific product names/codes."
      ],
      "id": "7c1eaab5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import vxdb\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "products = [\n",
        "    {\"id\": \"MBP-M4\",    \"text\": \"MacBook Pro M4 Max — 16-inch laptop with Apple silicon, 48GB unified memory, ideal for video editing and machine learning workloads.\",    \"category\": \"laptop\",    \"price\": 3499},\n",
        "    {\"id\": \"RTX-5090\",   \"text\": \"NVIDIA GeForce RTX 5090 — flagship GPU with 32GB GDDR7, ray tracing, and DLSS 4 for gaming and AI inference at 4K resolution.\",          \"category\": \"gpu\",       \"price\": 1999},\n",
        "    {\"id\": \"T14s-G6\",    \"text\": \"ThinkPad T14s Gen 6 — ultralight business laptop with AMD Ryzen AI processor, 14-inch OLED display, and all-day battery life.\",           \"category\": \"laptop\",    \"price\": 1429},\n",
        "    {\"id\": \"H100-SXM\",   \"text\": \"NVIDIA H100 SXM — datacenter GPU designed for large-scale AI training, transformer models, and high-performance computing clusters.\",     \"category\": \"gpu\",       \"price\": 30000},\n",
        "    {\"id\": \"MBA-M4\",     \"text\": \"MacBook Air M4 — ultra-thin 13-inch laptop with fanless design, 18-hour battery, perfect for students and everyday productivity.\",         \"category\": \"laptop\",    \"price\": 1099},\n",
        "    {\"id\": \"4090D\",      \"text\": \"NVIDIA GeForce RTX 4090 — previous generation flagship with 24GB GDDR6X, excellent for deep learning research and 4K gaming.\",             \"category\": \"gpu\",       \"price\": 1599},\n",
        "    {\"id\": \"XPS-16\",     \"text\": \"Dell XPS 16 — premium 16-inch laptop with Intel Core Ultra, NVIDIA RTX 4070, and a stunning 4K OLED touchscreen for creative professionals.\",\"category\": \"laptop\",  \"price\": 2199},\n",
        "    {\"id\": \"A6000\",      \"text\": \"NVIDIA RTX A6000 — professional workstation GPU with 48GB GDDR6 for CAD, 3D rendering, scientific visualization, and AI development.\",     \"category\": \"gpu\",       \"price\": 4650},\n",
        "    {\"id\": \"FW-16\",      \"text\": \"Framework Laptop 16 — modular, repairable laptop with swappable GPU module, mechanical keyboard, and open-source firmware.\",                \"category\": \"laptop\",    \"price\": 1399},\n",
        "    {\"id\": \"RX-9070\",    \"text\": \"AMD Radeon RX 9070 XT — mid-range GPU with 16GB GDDR6 and FSR 4 upscaling, competitive performance for 1440p gaming.\",                     \"category\": \"gpu\",       \"price\": 549},\n",
        "]\n",
        "\n",
        "texts = [p[\"text\"] for p in products]\n",
        "vectors = model.encode(texts).tolist()\n",
        "\n",
        "db = vxdb.Database()\n",
        "collection = db.create_collection(\"products\", dimension=384, metric=\"cosine\")\n",
        "\n",
        "collection.upsert(\n",
        "    ids=[p[\"id\"] for p in products],\n",
        "    vectors=vectors,\n",
        "    metadata=[{\"category\": p[\"category\"], \"price\": p[\"price\"]} for p in products],\n",
        "    documents=texts,\n",
        ")\n",
        "\n",
        "print(f\"Indexed {collection.count()} products\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f52a8734"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 1: When vector search alone falls short\n",
        "\n",
        "Embeddings capture *meaning* but may miss specific product codes or model names. Let's see what happens when a user searches for a specific product."
      ],
      "id": "49e49c22"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def compare_search(query: str, top_k: int = 5):\n",
        "    \"\"\"Run all three search modes and compare results side by side.\"\"\"\n",
        "    q_vec = model.encode([query]).tolist()[0]\n",
        "\n",
        "    print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "    vec_results = collection.query(vector=q_vec, top_k=top_k)\n",
        "    kw_results = collection.keyword_search(query=query, top_k=top_k)\n",
        "    hybrid_results = collection.hybrid_query(vector=q_vec, query=query, top_k=top_k, alpha=0.5)\n",
        "\n",
        "    print(f\"{'Rank':<6} {'Vector Search':<20} {'Keyword Search':<20} {'Hybrid (α=0.5)':<20}\")\n",
        "    print(\"-\" * 66)\n",
        "    for i in range(top_k):\n",
        "        v = vec_results[i][\"id\"] if i < len(vec_results) else \"-\"\n",
        "        k = kw_results[i][\"id\"] if i < len(kw_results) else \"-\"\n",
        "        h = hybrid_results[i][\"id\"] if i < len(hybrid_results) else \"-\"\n",
        "        print(f\"  {i+1:<4} {v:<20} {k:<20} {h:<20}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "# A user searching for a specific product code\n",
        "compare_search(\"RTX 5090\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "06e6cbd8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 2: Natural language queries\n",
        "\n",
        "For broad, meaning-based queries, vector search tends to do well. Let's see if hybrid still adds value."
      ],
      "id": "8a985bb7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "compare_search(\"lightweight laptop for students with long battery life\")\n",
        "compare_search(\"best GPU for training large transformer models\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "793cf0a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 3: Tuning alpha\n",
        "\n",
        "Let's sweep across different `alpha` values to see how the ranking changes for a mixed query (both semantic meaning and specific terms)."
      ],
      "id": "636c18f2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query = \"MacBook for machine learning\"\n",
        "q_vec = model.encode([query]).tolist()[0]\n",
        "\n",
        "alphas = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "header = f\"{'Rank':<6}\" + \"\".join(f\"{'α=' + str(a):<15}\" for a in alphas)\n",
        "print(header)\n",
        "print(\"-\" * len(header))\n",
        "\n",
        "for rank in range(5):\n",
        "    row = f\"  {rank+1:<4}\"\n",
        "    for alpha in alphas:\n",
        "        results = collection.hybrid_query(vector=q_vec, query=query, top_k=5, alpha=alpha)\n",
        "        doc_id = results[rank][\"id\"] if rank < len(results) else \"-\"\n",
        "        row += f\"{doc_id:<15}\"\n",
        "    print(row)\n",
        "\n",
        "print(\"\"\"\n",
        "Observations:\n",
        "• α=0.0 (pure keyword): Finds docs with \"MacBook\" and \"machine learning\" terms\n",
        "• α=1.0 (pure vector): Finds semantically similar docs (may miss exact term matches)\n",
        "• α=0.5 (balanced):    Best of both — ranks docs that match both meaning AND keywords higher\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "5e4a1cd2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 4: Hybrid + metadata filters\n",
        "\n",
        "You can combine hybrid search with metadata filters for powerful, precise retrieval."
      ],
      "id": "20c47753"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hybrid search, then post-filter to GPUs under $2000\n",
        "query = \"best GPU for deep learning under 2000 dollars\"\n",
        "q_vec = model.encode([query]).tolist()[0]\n",
        "\n",
        "# Vector + filter\n",
        "print(\"Vector search (GPUs under $2000):\")\n",
        "for r in collection.query(\n",
        "    vector=q_vec, top_k=5,\n",
        "    filter={\"$and\": [{\"category\": {\"$eq\": \"gpu\"}}, {\"price\": {\"$lte\": 2000}}]}\n",
        "):\n",
        "    print(f\"  → {r['id']:>10}  score={r['score']:.4f}  ${r['metadata']['price']}\")\n",
        "\n",
        "# Keyword search (no filter needed to compare)\n",
        "print(\"\\nKeyword search (all):\")\n",
        "for r in collection.keyword_search(query=\"deep learning GPU\", top_k=5):\n",
        "    print(f\"  → {r['id']:>10}  score={r['score']:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "cc84f415"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: When to use what\n",
        "\n",
        "| Search Mode | Best For | Example Query |\n",
        "|------------|---------|---------------|\n",
        "| **Vector only** (`query`) | Broad semantic questions | \"lightweight laptop for students\" |\n",
        "| **Keyword only** (`keyword_search`) | Exact terms, codes, names | \"RTX 5090\" |\n",
        "| **Hybrid** (`hybrid_query`) | Mixed intent, best default | \"MacBook for machine learning\" |\n",
        "| **Filtered** (`query` + `filter`) | Constrained search | \"GPU under $2000\" |\n",
        "\n",
        "**Rule of thumb:** Start with `hybrid_query(alpha=0.5)` as your default. If you find it's returning too many irrelevant keyword matches, increase `alpha`. If users complain about missing exact matches, decrease `alpha`."
      ],
      "id": "e3d58d3a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}