{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentence Transformers + vxdb (Local, Free, No API Key)\n",
        "\n",
        "This notebook shows how to generate embeddings **locally** using [sentence-transformers](https://www.sbert.net/) and store them in vxdb.\n",
        "\n",
        "**Why sentence-transformers?**\n",
        "- Runs 100% locally — no API key, no internet needed after model download\n",
        "- Free and open-source\n",
        "- Great for privacy-sensitive data\n",
        "- Many pre-trained models on Hugging Face\n",
        "\n",
        "**Model used:** `all-MiniLM-L6-v2` (384 dimensions, ~80 MB, very fast)\n",
        "\n",
        "Other good options:\n",
        "| Model | Dims | Size | Quality |\n",
        "|-------|------|------|---------|\n",
        "| `all-MiniLM-L6-v2` | 384 | 80 MB | Good (fast) |\n",
        "| `all-mpnet-base-v2` | 768 | 420 MB | Better |\n",
        "| `BAAI/bge-small-en-v1.5` | 384 | 130 MB | Great |\n",
        "| `BAAI/bge-large-en-v1.5` | 1024 | 1.3 GB | Best |\n",
        "\n",
        "**Prerequisites:**\n",
        "```bash\n",
        "pip install vxdb sentence-transformers\n",
        "```"
      ],
      "id": "419cf871"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install vxdb sentence-transformers -q"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "6e1d3a2c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load the model\n",
        "\n",
        "The model is downloaded once from Hugging Face (~80 MB) and cached locally."
      ],
      "id": "593a88ca"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "EMBEDDING_DIM = model.get_sentence_embedding_dimension()\n",
        "print(f\"Model loaded: all-MiniLM-L6-v2 ({EMBEDDING_DIM} dimensions)\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d828a52f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Prepare documents\n",
        "\n",
        "We'll use a small knowledge base about programming languages."
      ],
      "id": "cad209f2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "documents = [\n",
        "    {\"id\": \"python\",     \"text\": \"Python is a high-level interpreted language known for its readability and vast ecosystem of libraries for data science and web development.\"},\n",
        "    {\"id\": \"rust\",       \"text\": \"Rust is a systems programming language focused on safety, speed, and concurrency without a garbage collector.\"},\n",
        "    {\"id\": \"javascript\", \"text\": \"JavaScript is the language of the web, running in browsers and on servers via Node.js, powering interactive user interfaces.\"},\n",
        "    {\"id\": \"go\",         \"text\": \"Go is a statically typed compiled language designed at Google for simplicity, reliability, and efficient concurrency with goroutines.\"},\n",
        "    {\"id\": \"cpp\",        \"text\": \"C++ is a powerful systems language offering low-level memory control and high performance for games, databases, and operating systems.\"},\n",
        "    {\"id\": \"typescript\",  \"text\": \"TypeScript extends JavaScript with static types, catching errors at compile time while remaining compatible with the JS ecosystem.\"},\n",
        "    {\"id\": \"java\",       \"text\": \"Java is a class-based object-oriented language that runs on the JVM, widely used in enterprise applications and Android development.\"},\n",
        "    {\"id\": \"swift\",      \"text\": \"Swift is Apple's modern programming language for iOS and macOS development, combining safety with high performance.\"},\n",
        "]\n",
        "\n",
        "texts = [d[\"text\"] for d in documents]\n",
        "print(f\"Prepared {len(documents)} documents\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4b490540"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Embed and index\n",
        "\n",
        "`model.encode()` returns numpy arrays — we convert to plain Python lists for vxdb."
      ],
      "id": "54da8c0f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import vxdb\n",
        "\n",
        "# Encode all documents at once (batched for speed)\n",
        "vectors = model.encode(texts).tolist()  # numpy → list[list[float]]\n",
        "\n",
        "db = vxdb.Database()\n",
        "collection = db.create_collection(\n",
        "    name=\"languages\",\n",
        "    dimension=EMBEDDING_DIM,\n",
        "    metric=\"cosine\",\n",
        ")\n",
        "\n",
        "collection.upsert(\n",
        "    ids=[d[\"id\"] for d in documents],\n",
        "    vectors=vectors,\n",
        "    documents=texts,  # enable hybrid search\n",
        ")\n",
        "\n",
        "print(f\"Indexed {collection.count()} documents ({EMBEDDING_DIM}-dim local embeddings)\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4dd6a263"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Semantic search"
      ],
      "id": "0fac3a35"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "queries = [\n",
        "    \"What language is best for building fast, safe backend services?\",\n",
        "    \"I want to build a web app with a nice UI\",\n",
        "    \"Which language should I use for data analysis?\",\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    query_vec = model.encode([query]).tolist()[0]\n",
        "    results = collection.query(vector=query_vec, top_k=3)\n",
        "\n",
        "    print(f\"Q: {query}\")\n",
        "    for r in results:\n",
        "        print(f\"   → {r['id']:>12}  score={r['score']:.4f}\")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "b6b4d8df"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Hybrid search\n",
        "\n",
        "Combine the semantic understanding of the embedding model with exact keyword matching."
      ],
      "id": "651dace8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query = \"garbage collector memory safety\"\n",
        "query_vec = model.encode([query]).tolist()[0]\n",
        "\n",
        "# Compare: vector-only vs hybrid\n",
        "print(\"Vector-only search:\")\n",
        "for r in collection.query(vector=query_vec, top_k=3):\n",
        "    print(f\"   → {r['id']:>12}  score={r['score']:.4f}\")\n",
        "\n",
        "print(\"\\nHybrid search (alpha=0.5):\")\n",
        "for r in collection.hybrid_query(vector=query_vec, query=query, top_k=3, alpha=0.5):\n",
        "    print(f\"   → {r['id']:>12}  score={r['score']:.4f}\")\n",
        "\n",
        "print(\"\\nKeyword-only search:\")\n",
        "for r in collection.keyword_search(query=query, top_k=3):\n",
        "    print(f\"   → {r['id']:>12}  score={r['score']:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9abb4727"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bonus: Pluggable EmbeddingFunction wrapper\n",
        "\n",
        "Clean, reusable class that fits vxdb's interface:"
      ],
      "id": "6389168c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from vxdb.embedding import EmbeddingFunction\n",
        "\n",
        "\n",
        "class SentenceTransformerEmbedding(EmbeddingFunction):\n",
        "    \"\"\"Local embedding using any sentence-transformers model.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.dimension = self.model.get_sentence_embedding_dimension()\n",
        "\n",
        "    def embed(self, texts: list[str]) -> list[list[float]]:\n",
        "        return self.model.encode(texts).tolist()\n",
        "\n",
        "\n",
        "# Usage:\n",
        "embedder = SentenceTransformerEmbedding()\n",
        "vecs = embedder.embed([\"This runs entirely on your machine.\"])\n",
        "print(f\"Local embedding: {len(vecs[0])} dimensions, no API key needed!\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4cafb336"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}