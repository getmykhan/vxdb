---
title: Sentence Transformers
description: "Generate embeddings locally for free with sentence-transformers. No API key needed."
---

## Setup

```bash
pip install vxdb sentence-transformers
```

No API key. No internet after the initial model download. 100% local and free.

## Available models

| Model | Dimensions | Size | Quality |
|---|---|---|---|
| `all-MiniLM-L6-v2` | 384 | 80 MB | Good (fast) |
| `all-mpnet-base-v2` | 768 | 420 MB | Better |
| `BAAI/bge-small-en-v1.5` | 384 | 130 MB | Great |
| `BAAI/bge-large-en-v1.5` | 1024 | 1.3 GB | Best |

## Load the model

The model is downloaded once from Hugging Face and cached locally.

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")
EMBEDDING_DIM = model.get_sentence_embedding_dimension()  # 384
```

## Index documents

```python
import vxdb

documents = [
    {"id": "python", "text": "Python is a high-level interpreted language known for readability and data science."},
    {"id": "rust", "text": "Rust is a systems programming language focused on safety and speed."},
    {"id": "go", "text": "Go is a statically typed language designed for simplicity and efficient concurrency."},
]

texts = [d["text"] for d in documents]
vectors = model.encode(texts).tolist()

db = vxdb.Database()
collection = db.create_collection("languages", dimension=EMBEDDING_DIM, metric="cosine")

collection.upsert(
    ids=[d["id"] for d in documents],
    vectors=vectors,
    documents=texts,
)
```

<Tip>
`model.encode()` returns numpy arrays. Call `.tolist()` to convert to plain Python lists for vxdb.
</Tip>

## Search

```python
query_vec = model.encode(["What language is best for fast backend services?"]).tolist()[0]
results = collection.query(vector=query_vec, top_k=3)
```

## Hybrid search comparison

```python
query = "garbage collector memory safety"
query_vec = model.encode([query]).tolist()[0]

# Vector only
collection.query(vector=query_vec, top_k=3)

# Hybrid (vector + keyword)
collection.hybrid_query(vector=query_vec, query=query, top_k=3, alpha=0.5)

# Keyword only
collection.keyword_search(query=query, top_k=3)
```

## Reusable EmbeddingFunction wrapper

```python
from vxdb.embedding import EmbeddingFunction

class SentenceTransformerEmbedding(EmbeddingFunction):
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)
        self.dimension = self.model.get_sentence_embedding_dimension()

    def embed(self, texts: list[str]) -> list[list[float]]:
        return self.model.encode(texts).tolist()

embedder = SentenceTransformerEmbedding()
vecs = embedder.embed(["This runs entirely on your machine."])
```
